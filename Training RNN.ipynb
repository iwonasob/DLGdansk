{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "import numpy as np\n",
    "import librosa, librosa.display, IPython.display as ipd\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "np.random.seed(1515)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "sess = tf.Session(config=config) \n",
    "    \n",
    "import keras \n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras\n",
    "\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, LSTM, GRU, Bidirectional\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SET PATHS\n",
    "dataspace = '/vol/vssp/datasets/audio01/UrbanSound8K/audio/'\n",
    "projectspace = '/vol/vssp/AcousticEventsDetection/DLGdansk/UrbanSound/'\n",
    "\n",
    "metadatafile = '/vol/vssp/datasets/audio01/UrbanSound8K/metadata/UrbanSound8K.csv'\n",
    "metadata = pd.read_csv(metadatafile)\n",
    "\n",
    "hdf5_path = os.path.join(projectspace,'dataset.hdf5') \n",
    "modelfolder = os.path.join(projectspace,'models')\n",
    "scalerpath = os.path.join(projectspace,'scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "hf = h5py.File(hdf5_path, 'r')\n",
    "X_train = np.array(hf.get('X_train') )\n",
    "y_train = np.array(hf.get('y_train'))\n",
    "X_val =  np.array(hf.get('X_val'))\n",
    "y_val= np.array(hf.get('y_val'))\n",
    "X_test = np.array(hf.get('X_test'))\n",
    "y_test = np.array(hf.get('y_test'))\n",
    "\n",
    "n_features= hf.get('n_features').value\n",
    "n_frames=hf.get('max_length_samp').value\n",
    "label_list= hf.get('label_list').value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCALE THE DATA\n",
    "scaler=pickle.load(open(scalerpath, 'rb'))\n",
    "\n",
    "X_train_scaled = [scaler.transform(x.T) for x in X_train]\n",
    "X_val_scaled = [scaler.transform(x.T) for x in X_val]\n",
    "X_test_scaled = [scaler.transform(x.T) for x in X_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "816"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rnn(n_frames=n_frames, n_features=n_features,\n",
    "                     n_classes=10):\n",
    "\n",
    "    # INPUT\n",
    "    x = Input(shape=(n_frames, n_features), dtype='float32')\n",
    "  \n",
    "    y= LSTM(120, return_sequences = True)(x)\n",
    "    #y= Dropout(0.5)(y)  \n",
    "    \n",
    "    y= LSTM(120)(y)\n",
    "    #y= Dropout(0.5)(y) \n",
    "\n",
    "    y = Dense(n_classes, activation='sigmoid')(y)\n",
    "\n",
    "    m = Model(inputs=x, outputs=y)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 173, 40)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 173, 120)          77280     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 120)               115680    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1210      \n",
      "=================================================================\n",
      "Total params: 194,170\n",
      "Trainable params: 194,170\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m = build_rnn(n_features=40,)\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7079 samples, validate on 816 samples\n",
      "Epoch 1/200\n",
      "7079/7079 [==============================] - 28s 4ms/step - loss: 1.8441 - acc: 0.3009 - val_loss: 1.8088 - val_acc: 0.3064\n",
      "Epoch 2/200\n",
      "7079/7079 [==============================] - 28s 4ms/step - loss: 1.5702 - acc: 0.4037 - val_loss: 1.6956 - val_acc: 0.3456\n",
      "Epoch 3/200\n",
      "7079/7079 [==============================] - 28s 4ms/step - loss: 1.5223 - acc: 0.4389 - val_loss: 1.5602 - val_acc: 0.4093\n",
      "Epoch 4/200\n",
      "7079/7079 [==============================] - 28s 4ms/step - loss: 1.3949 - acc: 0.4940 - val_loss: 1.4376 - val_acc: 0.4473\n",
      "Epoch 5/200\n",
      "7079/7079 [==============================] - 28s 4ms/step - loss: 1.3831 - acc: 0.5005 - val_loss: 1.6010 - val_acc: 0.4142\n",
      "Epoch 6/200\n",
      "7079/7079 [==============================] - 27s 4ms/step - loss: 1.3234 - acc: 0.5227 - val_loss: 1.4830 - val_acc: 0.4890\n",
      "Epoch 7/200\n",
      "7079/7079 [==============================] - 27s 4ms/step - loss: 1.2526 - acc: 0.5550 - val_loss: 1.5531 - val_acc: 0.4988\n",
      "Epoch 8/200\n",
      "7079/7079 [==============================] - 28s 4ms/step - loss: 1.2032 - acc: 0.5745 - val_loss: 1.3733 - val_acc: 0.5662\n",
      "Epoch 9/200\n",
      "7079/7079 [==============================] - 28s 4ms/step - loss: 1.1973 - acc: 0.5737 - val_loss: 1.4658 - val_acc: 0.5086\n",
      "Epoch 10/200\n",
      "7079/7079 [==============================] - 27s 4ms/step - loss: 1.1723 - acc: 0.5926 - val_loss: 1.6517 - val_acc: 0.4498\n",
      "Epoch 11/200\n",
      "7079/7079 [==============================] - 27s 4ms/step - loss: 1.1294 - acc: 0.6047 - val_loss: 1.4130 - val_acc: 0.5135\n",
      "Epoch 12/200\n",
      "7079/7079 [==============================] - 28s 4ms/step - loss: 1.0724 - acc: 0.6309 - val_loss: 1.3480 - val_acc: 0.5515\n",
      "Epoch 13/200\n",
      "7079/7079 [==============================] - 28s 4ms/step - loss: 1.2550 - acc: 0.5769 - val_loss: 1.9962 - val_acc: 0.3297\n",
      "Epoch 14/200\n",
      "7079/7079 [==============================] - 28s 4ms/step - loss: 1.4146 - acc: 0.4851 - val_loss: 1.6054 - val_acc: 0.4167\n",
      "Epoch 15/200\n",
      "7079/7079 [==============================] - 28s 4ms/step - loss: 1.2279 - acc: 0.5754 - val_loss: 1.5935 - val_acc: 0.4669\n",
      "Epoch 16/200\n",
      "7079/7079 [==============================] - 28s 4ms/step - loss: 1.2216 - acc: 0.5861 - val_loss: 1.5137 - val_acc: 0.5270\n",
      "Epoch 17/200\n",
      "7079/7079 [==============================] - 28s 4ms/step - loss: 1.1970 - acc: 0.5874 - val_loss: 1.4133 - val_acc: 0.5380\n",
      "Epoch 18/200\n",
      "7079/7079 [==============================] - 27s 4ms/step - loss: 1.0866 - acc: 0.6333 - val_loss: 1.5567 - val_acc: 0.5061\n",
      "Epoch 19/200\n",
      "7079/7079 [==============================] - 27s 4ms/step - loss: 1.0570 - acc: 0.6429 - val_loss: 1.5293 - val_acc: 0.4681\n",
      "Epoch 20/200\n",
      "7079/7079 [==============================] - 28s 4ms/step - loss: 1.0083 - acc: 0.6610 - val_loss: 1.4958 - val_acc: 0.5466\n",
      "Epoch 21/200\n",
      "7079/7079 [==============================] - 27s 4ms/step - loss: 1.0238 - acc: 0.6607 - val_loss: 1.5016 - val_acc: 0.5221\n",
      "Epoch 22/200\n",
      "7079/7079 [==============================] - 27s 4ms/step - loss: 1.0467 - acc: 0.6408 - val_loss: 1.6686 - val_acc: 0.4914\n",
      "Epoch 23/200\n",
      "7079/7079 [==============================] - 27s 4ms/step - loss: 0.9950 - acc: 0.6591 - val_loss: 1.5355 - val_acc: 0.5061\n",
      "Epoch 24/200\n",
      "7079/7079 [==============================] - 27s 4ms/step - loss: 0.9508 - acc: 0.6882 - val_loss: 1.4936 - val_acc: 0.5674\n",
      "Epoch 25/200\n",
      "7079/7079 [==============================] - 27s 4ms/step - loss: 0.8928 - acc: 0.7107 - val_loss: 1.3635 - val_acc: 0.5600\n",
      "Epoch 26/200\n",
      "7079/7079 [==============================] - 27s 4ms/step - loss: 0.8580 - acc: 0.7228 - val_loss: 1.4686 - val_acc: 0.5613\n",
      "Epoch 27/200\n",
      "7079/7079 [==============================] - 27s 4ms/step - loss: 0.7820 - acc: 0.7483 - val_loss: 1.4888 - val_acc: 0.5588\n",
      "Epoch 28/200\n",
      "7079/7079 [==============================] - 27s 4ms/step - loss: 0.7777 - acc: 0.7439 - val_loss: 1.4812 - val_acc: 0.5515\n",
      "Epoch 29/200\n",
      "7079/7079 [==============================] - 27s 4ms/step - loss: 0.7562 - acc: 0.7565 - val_loss: 1.5409 - val_acc: 0.5453\n",
      "Epoch 30/200\n",
      "7079/7079 [==============================] - 27s 4ms/step - loss: 0.8079 - acc: 0.7432 - val_loss: 1.7930 - val_acc: 0.4547\n",
      "Epoch 31/200\n",
      "7079/7079 [==============================] - 27s 4ms/step - loss: 0.9097 - acc: 0.6930 - val_loss: 1.3858 - val_acc: 0.5686\n",
      "Epoch 32/200\n",
      "7079/7079 [==============================] - 27s 4ms/step - loss: 0.7654 - acc: 0.7439 - val_loss: 1.6087 - val_acc: 0.5478\n",
      "Epoch 33/200\n",
      "7079/7079 [==============================] - 27s 4ms/step - loss: 0.7521 - acc: 0.7517 - val_loss: 1.4815 - val_acc: 0.5748\n",
      "Epoch 34/200\n",
      "7079/7079 [==============================] - 28s 4ms/step - loss: 0.6883 - acc: 0.7765 - val_loss: 1.5485 - val_acc: 0.5637\n",
      "Epoch 35/200\n",
      "7079/7079 [==============================] - 27s 4ms/step - loss: 0.6586 - acc: 0.7854 - val_loss: 1.5304 - val_acc: 0.5490\n",
      "Epoch 36/200\n",
      "7079/7079 [==============================] - 27s 4ms/step - loss: 0.6429 - acc: 0.7858 - val_loss: 1.5212 - val_acc: 0.5539\n",
      "Epoch 37/200\n",
      "7079/7079 [==============================] - 27s 4ms/step - loss: 0.5922 - acc: 0.8099 - val_loss: 1.3937 - val_acc: 0.6091\n",
      "Epoch 38/200\n",
      "6110/7079 [========================>.....] - ETA: 3s - loss: 0.6069 - acc: 0.8013"
     ]
    }
   ],
   "source": [
    "model_checkpoint = ModelCheckpoint(\n",
    "    os.path.join(modelfolder, 'rnn_epoch_{epoch:03d}_val_loss_{val_loss:.4f}.hdf5'),\n",
    "    monitor='val_loss', save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, verbose=1)\n",
    "callbacks = [early_stopping, model_checkpoint]\n",
    "\n",
    "history = m.fit(x=np.array(X_train_scaled), y=y_train, batch_size=130,\n",
    "                    epochs=200, verbose=True,\n",
    "                    validation_data=(np.array(X_val_scaled), y_val), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = m.predict(X_test, batch_size=130, verbose=1)\n",
    "y_predict=np.array([ np.argmax(p) for p in prediction])\n",
    "y_test_label = np.array([np.argmax(y) for y in y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "acc = np.sum(y_test_label==y_predict) / float(len(y_test_label))\n",
    "print('Accuracy: {:.2f}'.format(acc))\n",
    "\n",
    "cm = confusion_matrix(y_test_label, y_predict )\n",
    "sns.heatmap(cm, annot=True, annot_kws={\"size\": 14}, fmt='g', linewidths=.5, yticklabels=label_list,xticklabels=label_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
