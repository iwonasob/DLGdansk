{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# FIX ALL THE RANDOM VALUES TO GET REPRODUCIBLE RESULTS\n",
    "import os\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"0\"\n",
    "\n",
    "import random as rn\n",
    "rn.seed(1254)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1515)\n",
    "\n",
    "# SET NICE PLOTTING\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import h5py\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (14, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(2)\n",
    "\n",
    "config = tf.ConfigProto(\n",
    "    intra_op_parallelism_threads=1,\n",
    "    inter_op_parallelism_threads=1 \n",
    ")\n",
    "\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "sess = tf.Session(graph= tf.get_default_graph(), config=config) \n",
    "    \n",
    "import keras \n",
    "from keras import backend as K\n",
    "K.set_session(sess)  # set this TensorFlow session as the default session for Keras\n",
    "\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, LSTM, GRU, Bidirectional\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#SET PATHS\n",
    "workspace = '/home/speakers/isobieraj/workspace'\n",
    "\n",
    "hdf5_path = os.path.join(workspace,'dataset.hdf5') \n",
    "modelfolder = os.path.join(workspace,'models')\n",
    "scalerpath = os.path.join(workspace,'scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "hf = h5py.File(hdf5_path, 'r')\n",
    "X_train = np.array(hf.get('X_train') )\n",
    "y_train = np.array(hf.get('y_train'))\n",
    "X_val =  np.array(hf.get('X_val'))\n",
    "y_val= np.array(hf.get('y_val'))\n",
    "X_test = np.array(hf.get('X_test'))\n",
    "y_test = np.array(hf.get('y_test'))\n",
    "\n",
    "n_features= hf.get('n_features').value\n",
    "n_frames=hf.get('max_length_samp').value\n",
    "label_list= hf.get('label_list').value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# SCALE THE DATA\n",
    "scaler = pickle.load(open(scalerpath, 'rb'), encoding='latin1') #python2 object to python3\n",
    "\n",
    "#scaler=pickle.load(open(scalerpath, 'rb'))\n",
    "\n",
    "X_train_scaled = [scaler.transform(x.T) for x in X_train]\n",
    "X_val_scaled = [scaler.transform(x.T) for x in X_val]\n",
    "X_test_scaled = [scaler.transform(x.T) for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def build_rnn(n_frames=n_frames, n_features=n_features,\n",
    "                     n_classes=10):\n",
    "\n",
    "    # INPUT\n",
    "    x = Input(shape=(n_frames, n_features), dtype='float32')\n",
    "  \n",
    "    y= LSTM(20, return_sequences = True)(x)\n",
    "    y= Dropout(0.5)(y)  \n",
    "    \n",
    "    y= LSTM(20)(y)\n",
    "    y= Dropout(0.5)(y) \n",
    "\n",
    "    y = Dense(n_classes, activation='softmax')(y)\n",
    "\n",
    "    m = Model(inputs=x, outputs=y)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 173, 40)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 173, 20)           4880      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 173, 20)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 8,370\n",
      "Trainable params: 8,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m = build_rnn(n_features=40,)\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(m, to_file='figures/rnn_model_shape.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<img src='figures/rnn_model_shape.png'> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "adam= keras.optimizers.Adam(lr=0.001, decay=1e-5)\n",
    "m.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7079 samples, validate on 816 samples\n",
      "Epoch 1/300\n",
      "7079/7079 [==============================] - 16s 2ms/step - loss: 2.2088 - acc: 0.1721 - val_loss: 2.0274 - val_acc: 0.2635\n",
      "Epoch 2/300\n",
      "7079/7079 [==============================] - 15s 2ms/step - loss: 2.0249 - acc: 0.2431 - val_loss: 1.8886 - val_acc: 0.2537\n",
      "Epoch 3/300\n",
      "7079/7079 [==============================] - 15s 2ms/step - loss: 1.9281 - acc: 0.2705 - val_loss: 1.8063 - val_acc: 0.2941\n",
      "Epoch 4/300\n",
      "7079/7079 [==============================] - 16s 2ms/step - loss: 1.8037 - acc: 0.3224 - val_loss: 1.6423 - val_acc: 0.3272\n",
      "Epoch 5/300\n",
      "7079/7079 [==============================] - 16s 2ms/step - loss: 1.7459 - acc: 0.3633 - val_loss: 1.6612 - val_acc: 0.3150\n",
      "Epoch 6/300\n",
      "7079/7079 [==============================] - 16s 2ms/step - loss: 1.7785 - acc: 0.3618 - val_loss: 1.7074 - val_acc: 0.2745\n",
      "Epoch 7/300\n",
      "7079/7079 [==============================] - 16s 2ms/step - loss: 1.7342 - acc: 0.3666 - val_loss: 1.5701 - val_acc: 0.3701\n",
      "Epoch 8/300\n",
      "7079/7079 [==============================] - 16s 2ms/step - loss: 1.6922 - acc: 0.3808 - val_loss: 1.5348 - val_acc: 0.3627\n",
      "Epoch 9/300\n",
      "7079/7079 [==============================] - 16s 2ms/step - loss: 1.6327 - acc: 0.4005 - val_loss: 1.5247 - val_acc: 0.3824\n",
      "Epoch 10/300\n",
      "7079/7079 [==============================] - 16s 2ms/step - loss: 1.5983 - acc: 0.4146 - val_loss: 1.5727 - val_acc: 0.3603\n",
      "Epoch 11/300\n",
      "7079/7079 [==============================] - 16s 2ms/step - loss: 1.5814 - acc: 0.4297 - val_loss: 1.5450 - val_acc: 0.3995\n",
      "Epoch 12/300\n",
      "7079/7079 [==============================] - 16s 2ms/step - loss: 1.5681 - acc: 0.4354 - val_loss: 1.5426 - val_acc: 0.3811\n",
      "Epoch 13/300\n",
      "7079/7079 [==============================] - 16s 2ms/step - loss: 1.6012 - acc: 0.4292 - val_loss: 1.5420 - val_acc: 0.3713\n",
      "Epoch 14/300\n",
      "7079/7079 [==============================] - 16s 2ms/step - loss: 1.5573 - acc: 0.4378 - val_loss: 1.4511 - val_acc: 0.4191\n",
      "Epoch 15/300\n",
      "7079/7079 [==============================] - 16s 2ms/step - loss: 1.5702 - acc: 0.4383 - val_loss: 1.4450 - val_acc: 0.4498\n",
      "Epoch 16/300\n",
      "7079/7079 [==============================] - 16s 2ms/step - loss: 1.5889 - acc: 0.4229 - val_loss: 1.5208 - val_acc: 0.4632\n",
      "Epoch 17/300\n",
      "7079/7079 [==============================] - 16s 2ms/step - loss: 1.6248 - acc: 0.4167 - val_loss: 1.5363 - val_acc: 0.4375\n",
      "Epoch 18/300\n",
      "7079/7079 [==============================] - 16s 2ms/step - loss: 1.6011 - acc: 0.4283 - val_loss: 1.5913 - val_acc: 0.4142\n",
      "Epoch 19/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.8633 - acc: 0.3437 - val_loss: 1.6479 - val_acc: 0.4056\n",
      "Epoch 20/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.6900 - acc: 0.3783 - val_loss: 1.5602 - val_acc: 0.4093\n",
      "Epoch 21/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.6243 - acc: 0.4125 - val_loss: 1.5612 - val_acc: 0.3811\n",
      "Epoch 22/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.6063 - acc: 0.4114 - val_loss: 1.5638 - val_acc: 0.4007\n",
      "Epoch 23/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.5825 - acc: 0.4268 - val_loss: 1.4982 - val_acc: 0.4498\n",
      "Epoch 24/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.5588 - acc: 0.4369 - val_loss: 1.5284 - val_acc: 0.4277\n",
      "Epoch 25/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.5274 - acc: 0.4578 - val_loss: 1.5232 - val_acc: 0.4387\n",
      "Epoch 26/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.5282 - acc: 0.4516 - val_loss: 1.5869 - val_acc: 0.4130\n",
      "Epoch 27/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.6379 - acc: 0.4277 - val_loss: 1.6545 - val_acc: 0.3738\n",
      "Epoch 28/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.5261 - acc: 0.4515 - val_loss: 1.5560 - val_acc: 0.3983\n",
      "Epoch 29/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.5172 - acc: 0.4698 - val_loss: 1.4756 - val_acc: 0.4449\n",
      "Epoch 30/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.5516 - acc: 0.4461 - val_loss: 1.5146 - val_acc: 0.4338\n",
      "Epoch 31/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.5535 - acc: 0.4328 - val_loss: 1.5488 - val_acc: 0.4510\n",
      "Epoch 32/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.5300 - acc: 0.4453 - val_loss: 1.4675 - val_acc: 0.4988\n",
      "Epoch 33/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.4983 - acc: 0.4626 - val_loss: 1.4480 - val_acc: 0.4853\n",
      "Epoch 34/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.5806 - acc: 0.4269 - val_loss: 1.4432 - val_acc: 0.4792\n",
      "Epoch 35/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.5280 - acc: 0.4505 - val_loss: 1.4208 - val_acc: 0.5098\n",
      "Epoch 36/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.5050 - acc: 0.4601 - val_loss: 1.5450 - val_acc: 0.4424\n",
      "Epoch 37/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.4837 - acc: 0.4746 - val_loss: 1.4870 - val_acc: 0.4547\n",
      "Epoch 38/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.5342 - acc: 0.4649 - val_loss: 1.5264 - val_acc: 0.4498\n",
      "Epoch 39/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.4956 - acc: 0.4710 - val_loss: 1.4998 - val_acc: 0.4485\n",
      "Epoch 40/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.4435 - acc: 0.4926 - val_loss: 1.4536 - val_acc: 0.4743\n",
      "Epoch 41/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.4396 - acc: 0.4924 - val_loss: 1.5268 - val_acc: 0.4191\n",
      "Epoch 42/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.4468 - acc: 0.4886 - val_loss: 1.5700 - val_acc: 0.4228\n",
      "Epoch 43/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.4821 - acc: 0.4775 - val_loss: 1.4940 - val_acc: 0.4951\n",
      "Epoch 44/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.4290 - acc: 0.4946 - val_loss: 1.4500 - val_acc: 0.4951\n",
      "Epoch 45/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.4157 - acc: 0.4981 - val_loss: 1.5304 - val_acc: 0.4975\n",
      "Epoch 46/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.3947 - acc: 0.5095 - val_loss: 1.4626 - val_acc: 0.5368\n",
      "Epoch 47/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.3977 - acc: 0.5149 - val_loss: 1.4990 - val_acc: 0.4449\n",
      "Epoch 48/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.3850 - acc: 0.5194 - val_loss: 1.7269 - val_acc: 0.4326\n",
      "Epoch 49/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.5413 - acc: 0.4667 - val_loss: 1.5533 - val_acc: 0.4203\n",
      "Epoch 50/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.4327 - acc: 0.4951 - val_loss: 1.4979 - val_acc: 0.4449\n",
      "Epoch 51/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.4135 - acc: 0.5070 - val_loss: 1.4865 - val_acc: 0.4657\n",
      "Epoch 52/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.4028 - acc: 0.5036 - val_loss: 1.4221 - val_acc: 0.4828\n",
      "Epoch 53/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.3512 - acc: 0.5190 - val_loss: 1.4696 - val_acc: 0.4596\n",
      "Epoch 54/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.4010 - acc: 0.5118 - val_loss: 1.6501 - val_acc: 0.4326\n",
      "Epoch 55/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.4779 - acc: 0.4821 - val_loss: 1.6380 - val_acc: 0.4314\n",
      "Epoch 56/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 2.0223 - acc: 0.3297 - val_loss: 1.6522 - val_acc: 0.4657\n",
      "Epoch 57/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.6893 - acc: 0.3797 - val_loss: 1.5881 - val_acc: 0.4804\n",
      "Epoch 58/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.5786 - acc: 0.4344 - val_loss: 1.5588 - val_acc: 0.4718\n",
      "Epoch 59/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.5159 - acc: 0.4650 - val_loss: 1.5006 - val_acc: 0.5110\n",
      "Epoch 60/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.4948 - acc: 0.4704 - val_loss: 1.4938 - val_acc: 0.4816\n",
      "Epoch 61/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.7551 - acc: 0.4212 - val_loss: 1.8067 - val_acc: 0.4314\n",
      "Epoch 62/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.8225 - acc: 0.3645 - val_loss: 1.7696 - val_acc: 0.3382\n",
      "Epoch 63/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.6765 - acc: 0.4027 - val_loss: 1.6362 - val_acc: 0.3787\n",
      "Epoch 64/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.6240 - acc: 0.4174 - val_loss: 1.5887 - val_acc: 0.3922\n",
      "Epoch 65/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.5797 - acc: 0.4347 - val_loss: 1.6039 - val_acc: 0.3958\n",
      "Epoch 66/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.5540 - acc: 0.4570 - val_loss: 1.6037 - val_acc: 0.3848\n",
      "Epoch 67/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.5344 - acc: 0.4614 - val_loss: 1.5564 - val_acc: 0.4154\n",
      "Epoch 68/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.4936 - acc: 0.4761 - val_loss: 1.5297 - val_acc: 0.4154\n",
      "Epoch 69/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.4958 - acc: 0.4741 - val_loss: 1.5211 - val_acc: 0.4203\n",
      "Epoch 70/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.4836 - acc: 0.4713 - val_loss: 1.4745 - val_acc: 0.4350\n",
      "Epoch 71/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.4992 - acc: 0.4701 - val_loss: 1.4531 - val_acc: 0.4681\n",
      "Epoch 72/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.6433 - acc: 0.4265 - val_loss: 1.6168 - val_acc: 0.3958\n",
      "Epoch 73/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.5048 - acc: 0.4746 - val_loss: 1.4737 - val_acc: 0.4105\n",
      "Epoch 74/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.4525 - acc: 0.4865 - val_loss: 1.4723 - val_acc: 0.4473\n",
      "Epoch 75/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.4212 - acc: 0.4999 - val_loss: 1.4253 - val_acc: 0.4608\n",
      "Epoch 76/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.4573 - acc: 0.4939 - val_loss: 1.7215 - val_acc: 0.3934\n",
      "Epoch 77/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.5017 - acc: 0.4600 - val_loss: 1.5157 - val_acc: 0.4093\n",
      "Epoch 78/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.4172 - acc: 0.5039 - val_loss: 1.4847 - val_acc: 0.4338\n",
      "Epoch 79/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.4234 - acc: 0.4985 - val_loss: 1.4386 - val_acc: 0.4706\n",
      "Epoch 80/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.4040 - acc: 0.5050 - val_loss: 1.5011 - val_acc: 0.4792\n",
      "Epoch 81/300\n",
      "7079/7079 [==============================] - 18s 3ms/step - loss: 1.3996 - acc: 0.5197 - val_loss: 1.4761 - val_acc: 0.5012\n",
      "Epoch 82/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.4011 - acc: 0.5094 - val_loss: 1.4536 - val_acc: 0.4877\n",
      "Epoch 83/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.3629 - acc: 0.5304 - val_loss: 1.4604 - val_acc: 0.4877\n",
      "Epoch 84/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.3776 - acc: 0.5255 - val_loss: 1.4974 - val_acc: 0.4718\n",
      "Epoch 85/300\n",
      "7079/7079 [==============================] - 22s 3ms/step - loss: 1.3986 - acc: 0.5169 - val_loss: 1.4922 - val_acc: 0.4694\n",
      "Epoch 86/300\n",
      "7079/7079 [==============================] - 39s 6ms/step - loss: 1.3529 - acc: 0.5313 - val_loss: 1.5242 - val_acc: 0.4632\n",
      "Epoch 87/300\n",
      "7079/7079 [==============================] - 39s 5ms/step - loss: 1.3477 - acc: 0.5416 - val_loss: 1.4460 - val_acc: 0.4877\n",
      "Epoch 88/300\n",
      "7079/7079 [==============================] - 39s 5ms/step - loss: 1.3229 - acc: 0.5460 - val_loss: 1.5739 - val_acc: 0.4694\n",
      "Epoch 89/300\n",
      "7079/7079 [==============================] - 37s 5ms/step - loss: 1.3329 - acc: 0.5494 - val_loss: 1.4700 - val_acc: 0.4890\n",
      "Epoch 90/300\n",
      "7079/7079 [==============================] - 31s 4ms/step - loss: 1.3058 - acc: 0.5502 - val_loss: 1.4484 - val_acc: 0.5257\n",
      "Epoch 91/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.4665 - acc: 0.5050 - val_loss: 1.5029 - val_acc: 0.4596\n",
      "Epoch 92/300\n",
      "7079/7079 [==============================] - 18s 2ms/step - loss: 1.3568 - acc: 0.5365 - val_loss: 1.5625 - val_acc: 0.4449\n",
      "Epoch 93/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.4334 - acc: 0.4994 - val_loss: 1.4472 - val_acc: 0.4890\n",
      "Epoch 94/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.3621 - acc: 0.5248 - val_loss: 1.4889 - val_acc: 0.4963\n",
      "Epoch 95/300\n",
      "7079/7079 [==============================] - 18s 2ms/step - loss: 1.3566 - acc: 0.5245 - val_loss: 1.5873 - val_acc: 0.4485\n",
      "Epoch 96/300\n",
      "7079/7079 [==============================] - 18s 2ms/step - loss: 1.3798 - acc: 0.5156 - val_loss: 1.4544 - val_acc: 0.5368\n",
      "Epoch 97/300\n",
      "7079/7079 [==============================] - 18s 2ms/step - loss: 1.3235 - acc: 0.5331 - val_loss: 1.4848 - val_acc: 0.5025\n",
      "Epoch 98/300\n",
      "7079/7079 [==============================] - 18s 2ms/step - loss: 1.2986 - acc: 0.5570 - val_loss: 1.3761 - val_acc: 0.5306\n",
      "Epoch 99/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.2874 - acc: 0.5628 - val_loss: 1.4754 - val_acc: 0.5306\n",
      "Epoch 100/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.2810 - acc: 0.5571 - val_loss: 1.4002 - val_acc: 0.5135\n",
      "Epoch 101/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.2878 - acc: 0.5547 - val_loss: 1.4107 - val_acc: 0.5147\n",
      "Epoch 102/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.2623 - acc: 0.5738 - val_loss: 1.4212 - val_acc: 0.5233\n",
      "Epoch 103/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.2444 - acc: 0.5761 - val_loss: 1.4995 - val_acc: 0.4841\n",
      "Epoch 104/300\n",
      "7079/7079 [==============================] - 39s 5ms/step - loss: 1.3719 - acc: 0.5279 - val_loss: 1.5257 - val_acc: 0.4828\n",
      "Epoch 105/300\n",
      "7079/7079 [==============================] - 37s 5ms/step - loss: 1.3742 - acc: 0.5313 - val_loss: 1.4224 - val_acc: 0.5172\n",
      "Epoch 106/300\n",
      "7079/7079 [==============================] - 37s 5ms/step - loss: 1.2638 - acc: 0.5653 - val_loss: 1.4730 - val_acc: 0.5196\n",
      "Epoch 107/300\n",
      "7079/7079 [==============================] - 38s 5ms/step - loss: 1.2527 - acc: 0.5820 - val_loss: 1.4254 - val_acc: 0.5319\n",
      "Epoch 108/300\n",
      "7079/7079 [==============================] - 25s 3ms/step - loss: 1.3295 - acc: 0.5519 - val_loss: 1.4208 - val_acc: 0.4988\n",
      "Epoch 109/300\n",
      "7079/7079 [==============================] - 34s 5ms/step - loss: 1.2382 - acc: 0.5783 - val_loss: 1.4015 - val_acc: 0.5147\n",
      "Epoch 110/300\n",
      "7079/7079 [==============================] - 34s 5ms/step - loss: 1.3050 - acc: 0.5701 - val_loss: 1.4034 - val_acc: 0.5343\n",
      "Epoch 111/300\n",
      "7079/7079 [==============================] - 34s 5ms/step - loss: 1.3979 - acc: 0.5449 - val_loss: 1.8798 - val_acc: 0.3897\n",
      "Epoch 112/300\n",
      "7079/7079 [==============================] - 35s 5ms/step - loss: 1.7587 - acc: 0.4123 - val_loss: 1.4747 - val_acc: 0.5098\n",
      "Epoch 113/300\n",
      "7079/7079 [==============================] - 35s 5ms/step - loss: 1.5042 - acc: 0.4608 - val_loss: 1.4317 - val_acc: 0.4853\n",
      "Epoch 114/300\n",
      "7079/7079 [==============================] - 18s 3ms/step - loss: 1.4199 - acc: 0.4920 - val_loss: 1.4676 - val_acc: 0.5392\n",
      "Epoch 115/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.3816 - acc: 0.5101 - val_loss: 1.4532 - val_acc: 0.5270\n",
      "Epoch 116/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.3466 - acc: 0.5316 - val_loss: 1.4262 - val_acc: 0.5110\n",
      "Epoch 117/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.3425 - acc: 0.5343 - val_loss: 1.4405 - val_acc: 0.5159\n",
      "Epoch 118/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.3247 - acc: 0.5511 - val_loss: 1.4243 - val_acc: 0.5221\n",
      "Epoch 119/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.2854 - acc: 0.5604 - val_loss: 1.5193 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.2903 - acc: 0.5577 - val_loss: 1.5048 - val_acc: 0.4951\n",
      "Epoch 121/300\n",
      "7079/7079 [==============================] - 18s 2ms/step - loss: 1.3042 - acc: 0.5563 - val_loss: 1.4020 - val_acc: 0.5319\n",
      "Epoch 122/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.3936 - acc: 0.5386 - val_loss: 1.4234 - val_acc: 0.5221\n",
      "Epoch 123/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.4872 - acc: 0.4841 - val_loss: 1.4724 - val_acc: 0.4804\n",
      "Epoch 124/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.3823 - acc: 0.5156 - val_loss: 1.5018 - val_acc: 0.4828\n",
      "Epoch 125/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.3225 - acc: 0.5495 - val_loss: 1.4566 - val_acc: 0.5233\n",
      "Epoch 126/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.2715 - acc: 0.5642 - val_loss: 1.4229 - val_acc: 0.5306\n",
      "Epoch 127/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.2686 - acc: 0.5673 - val_loss: 1.4454 - val_acc: 0.5319\n",
      "Epoch 128/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.2310 - acc: 0.5773 - val_loss: 1.4261 - val_acc: 0.5368\n",
      "Epoch 129/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.2250 - acc: 0.5885 - val_loss: 1.3632 - val_acc: 0.5527\n",
      "Epoch 130/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.2406 - acc: 0.5848 - val_loss: 1.5405 - val_acc: 0.5086\n",
      "Epoch 131/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.2226 - acc: 0.5995 - val_loss: 1.4935 - val_acc: 0.5282\n",
      "Epoch 132/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.1984 - acc: 0.6015 - val_loss: 1.5148 - val_acc: 0.5221\n",
      "Epoch 133/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.2123 - acc: 0.6029 - val_loss: 1.4637 - val_acc: 0.5392\n",
      "Epoch 134/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.2977 - acc: 0.5765 - val_loss: 1.4883 - val_acc: 0.5245\n",
      "Epoch 135/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.2758 - acc: 0.5768 - val_loss: 1.6817 - val_acc: 0.4743\n",
      "Epoch 136/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.2674 - acc: 0.5803 - val_loss: 1.5179 - val_acc: 0.4890\n",
      "Epoch 137/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.2002 - acc: 0.6066 - val_loss: 1.5970 - val_acc: 0.4902\n",
      "Epoch 138/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.2450 - acc: 0.5934 - val_loss: 1.6388 - val_acc: 0.4914\n",
      "Epoch 139/300\n",
      "7079/7079 [==============================] - 16s 2ms/step - loss: 1.2851 - acc: 0.5628 - val_loss: 1.5014 - val_acc: 0.5159\n",
      "Epoch 140/300\n",
      "7079/7079 [==============================] - 16s 2ms/step - loss: 1.1971 - acc: 0.6080 - val_loss: 1.4968 - val_acc: 0.5135\n",
      "Epoch 141/300\n",
      "7079/7079 [==============================] - 16s 2ms/step - loss: 1.1789 - acc: 0.6115 - val_loss: 1.4361 - val_acc: 0.5502\n",
      "Epoch 142/300\n",
      "7079/7079 [==============================] - 16s 2ms/step - loss: 1.1629 - acc: 0.6131 - val_loss: 1.5707 - val_acc: 0.4951\n",
      "Epoch 143/300\n",
      "7079/7079 [==============================] - 16s 2ms/step - loss: 1.1676 - acc: 0.6217 - val_loss: 1.5859 - val_acc: 0.4841\n",
      "Epoch 144/300\n",
      "7079/7079 [==============================] - 16s 2ms/step - loss: 1.1630 - acc: 0.6066 - val_loss: 1.5348 - val_acc: 0.5135\n",
      "Epoch 145/300\n",
      "7079/7079 [==============================] - 16s 2ms/step - loss: 1.1894 - acc: 0.6179 - val_loss: 1.4662 - val_acc: 0.5331\n",
      "Epoch 146/300\n",
      "7079/7079 [==============================] - 16s 2ms/step - loss: 1.1607 - acc: 0.6184 - val_loss: 1.4510 - val_acc: 0.5270\n",
      "Epoch 147/300\n",
      "7079/7079 [==============================] - 16s 2ms/step - loss: 1.1352 - acc: 0.6336 - val_loss: 1.5214 - val_acc: 0.5257\n",
      "Epoch 148/300\n",
      "7079/7079 [==============================] - 16s 2ms/step - loss: 1.1718 - acc: 0.6158 - val_loss: 1.3964 - val_acc: 0.5551\n",
      "Epoch 149/300\n",
      "7079/7079 [==============================] - 16s 2ms/step - loss: 1.1787 - acc: 0.6155 - val_loss: 1.4629 - val_acc: 0.5380\n",
      "Epoch 150/300\n",
      "7079/7079 [==============================] - 16s 2ms/step - loss: 1.3269 - acc: 0.5680 - val_loss: 1.5062 - val_acc: 0.5306\n",
      "Epoch 151/300\n",
      "7079/7079 [==============================] - 16s 2ms/step - loss: 1.2737 - acc: 0.5775 - val_loss: 1.5285 - val_acc: 0.5257\n",
      "Epoch 152/300\n",
      "7079/7079 [==============================] - 16s 2ms/step - loss: 1.2379 - acc: 0.5896 - val_loss: 1.6176 - val_acc: 0.4926\n",
      "Epoch 153/300\n",
      "7079/7079 [==============================] - 16s 2ms/step - loss: 1.2052 - acc: 0.6067 - val_loss: 1.4818 - val_acc: 0.5392\n",
      "Epoch 154/300\n",
      "7079/7079 [==============================] - 16s 2ms/step - loss: 1.1734 - acc: 0.6162 - val_loss: 1.5042 - val_acc: 0.5368\n",
      "Epoch 155/300\n",
      "7079/7079 [==============================] - 16s 2ms/step - loss: 1.1922 - acc: 0.6118 - val_loss: 1.4573 - val_acc: 0.5282\n",
      "Epoch 156/300\n",
      "7079/7079 [==============================] - 18s 3ms/step - loss: 1.1615 - acc: 0.6173 - val_loss: 1.5374 - val_acc: 0.5025\n",
      "Epoch 157/300\n",
      "7079/7079 [==============================] - 40s 6ms/step - loss: 1.1733 - acc: 0.6070 - val_loss: 1.4090 - val_acc: 0.5355\n",
      "Epoch 158/300\n",
      "7079/7079 [==============================] - 39s 5ms/step - loss: 1.2857 - acc: 0.5775 - val_loss: 1.4593 - val_acc: 0.5368\n",
      "Epoch 159/300\n",
      "7079/7079 [==============================] - 39s 6ms/step - loss: 1.1990 - acc: 0.5964 - val_loss: 1.4814 - val_acc: 0.5417\n",
      "Epoch 160/300\n",
      "7079/7079 [==============================] - 38s 5ms/step - loss: 1.2145 - acc: 0.6006 - val_loss: 1.4707 - val_acc: 0.4951\n",
      "Epoch 161/300\n",
      "7079/7079 [==============================] - 34s 5ms/step - loss: 1.2274 - acc: 0.5936 - val_loss: 1.4469 - val_acc: 0.5319\n",
      "Epoch 162/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.1854 - acc: 0.6196 - val_loss: 1.4247 - val_acc: 0.5404\n",
      "Epoch 163/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.6402 - acc: 0.5064 - val_loss: 1.9468 - val_acc: 0.3676\n",
      "Epoch 164/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.7584 - acc: 0.4160 - val_loss: 1.4441 - val_acc: 0.4951\n",
      "Epoch 165/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.4897 - acc: 0.4756 - val_loss: 1.3912 - val_acc: 0.5049\n",
      "Epoch 166/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.4133 - acc: 0.5030 - val_loss: 1.4237 - val_acc: 0.4890\n",
      "Epoch 167/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.3787 - acc: 0.5174 - val_loss: 1.3879 - val_acc: 0.5270\n",
      "Epoch 168/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.3120 - acc: 0.5509 - val_loss: 1.3822 - val_acc: 0.5110\n",
      "Epoch 169/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.2600 - acc: 0.5823 - val_loss: 1.4118 - val_acc: 0.5233\n",
      "Epoch 170/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.2012 - acc: 0.6100 - val_loss: 1.4134 - val_acc: 0.5270\n",
      "Epoch 171/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.1724 - acc: 0.6193 - val_loss: 1.3767 - val_acc: 0.5417\n",
      "Epoch 172/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.1468 - acc: 0.6296 - val_loss: 1.5380 - val_acc: 0.5086\n",
      "Epoch 173/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.3616 - acc: 0.5581 - val_loss: 1.5418 - val_acc: 0.5086\n",
      "Epoch 174/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.1849 - acc: 0.6091 - val_loss: 1.4963 - val_acc: 0.5404\n",
      "Epoch 175/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.1261 - acc: 0.6371 - val_loss: 1.4654 - val_acc: 0.5392\n",
      "Epoch 176/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.1293 - acc: 0.6357 - val_loss: 1.3735 - val_acc: 0.5723\n",
      "Epoch 177/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.1019 - acc: 0.6429 - val_loss: 1.4503 - val_acc: 0.5368\n",
      "Epoch 178/300\n",
      "7079/7079 [==============================] - 18s 3ms/step - loss: 1.0951 - acc: 0.6533 - val_loss: 1.6100 - val_acc: 0.5184\n",
      "Epoch 179/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.1281 - acc: 0.6371 - val_loss: 1.4384 - val_acc: 0.5441\n",
      "Epoch 180/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.1078 - acc: 0.6471 - val_loss: 1.3473 - val_acc: 0.5723\n",
      "Epoch 181/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.0913 - acc: 0.6481 - val_loss: 1.4514 - val_acc: 0.5478\n",
      "Epoch 182/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.0588 - acc: 0.6620 - val_loss: 1.4407 - val_acc: 0.5564\n",
      "Epoch 183/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.0509 - acc: 0.6564 - val_loss: 1.5097 - val_acc: 0.5306\n",
      "Epoch 184/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.1539 - acc: 0.6288 - val_loss: 1.5298 - val_acc: 0.5343\n",
      "Epoch 185/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.6102 - acc: 0.5012 - val_loss: 1.5474 - val_acc: 0.4951\n",
      "Epoch 186/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.4666 - acc: 0.5184 - val_loss: 1.3730 - val_acc: 0.5600\n",
      "Epoch 187/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.4275 - acc: 0.5156 - val_loss: 1.4557 - val_acc: 0.4743\n",
      "Epoch 188/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.3530 - acc: 0.5456 - val_loss: 1.4222 - val_acc: 0.5098\n",
      "Epoch 189/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.4599 - acc: 0.5085 - val_loss: 1.4612 - val_acc: 0.4865\n",
      "Epoch 190/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.2829 - acc: 0.5704 - val_loss: 1.4335 - val_acc: 0.5172\n",
      "Epoch 191/300\n",
      "7079/7079 [==============================] - 18s 2ms/step - loss: 1.2054 - acc: 0.6071 - val_loss: 1.4226 - val_acc: 0.5257\n",
      "Epoch 192/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.1419 - acc: 0.6312 - val_loss: 1.4205 - val_acc: 0.5319\n",
      "Epoch 193/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.1119 - acc: 0.6351 - val_loss: 1.4670 - val_acc: 0.5221\n",
      "Epoch 194/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.0772 - acc: 0.6495 - val_loss: 1.4416 - val_acc: 0.5417\n",
      "Epoch 195/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.0895 - acc: 0.6478 - val_loss: 1.3861 - val_acc: 0.5466\n",
      "Epoch 196/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.1187 - acc: 0.6353 - val_loss: 1.3852 - val_acc: 0.5429\n",
      "Epoch 197/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.1522 - acc: 0.6169 - val_loss: 1.4064 - val_acc: 0.5527\n",
      "Epoch 198/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.1179 - acc: 0.6430 - val_loss: 1.4238 - val_acc: 0.5441\n",
      "Epoch 199/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.0572 - acc: 0.6639 - val_loss: 1.3964 - val_acc: 0.5699\n",
      "Epoch 200/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.0627 - acc: 0.6655 - val_loss: 1.4772 - val_acc: 0.5527\n",
      "Epoch 201/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.0538 - acc: 0.6584 - val_loss: 1.5453 - val_acc: 0.5466\n",
      "Epoch 202/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.0414 - acc: 0.6702 - val_loss: 1.4530 - val_acc: 0.5588\n",
      "Epoch 203/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.0446 - acc: 0.6661 - val_loss: 1.3866 - val_acc: 0.5748\n",
      "Epoch 204/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.0076 - acc: 0.6805 - val_loss: 1.4485 - val_acc: 0.5637\n",
      "Epoch 205/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.0026 - acc: 0.6874 - val_loss: 1.4421 - val_acc: 0.5772\n",
      "Epoch 206/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.0319 - acc: 0.6723 - val_loss: 1.4894 - val_acc: 0.5723\n",
      "Epoch 207/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 0.9917 - acc: 0.6858 - val_loss: 1.4707 - val_acc: 0.5735\n",
      "Epoch 208/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 0.9913 - acc: 0.6860 - val_loss: 1.5031 - val_acc: 0.5539\n",
      "Epoch 209/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 0.9779 - acc: 0.6857 - val_loss: 1.5637 - val_acc: 0.5441\n",
      "Epoch 210/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.0099 - acc: 0.6810 - val_loss: 1.7348 - val_acc: 0.5159\n",
      "Epoch 211/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.0916 - acc: 0.6538 - val_loss: 1.4134 - val_acc: 0.5833\n",
      "Epoch 212/300\n",
      "7079/7079 [==============================] - 17s 2ms/step - loss: 1.0374 - acc: 0.6665 - val_loss: 1.4359 - val_acc: 0.5735\n",
      "Epoch 213/300\n",
      "3640/7079 [==============>...............] - ETA: 7s - loss: 1.0189 - acc: 0.6783"
     ]
    }
   ],
   "source": [
    "model_checkpoint = ModelCheckpoint(\n",
    "            os.path.join(modelfolder, \n",
    "                    'rnn_epoch_{epoch:03d}_val_loss_{val_loss:.4f}.hdf5'),\n",
    "            monitor='val_loss', \n",
    "            save_best_only=True)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, verbose=1)\n",
    "callbacks = [early_stopping, model_checkpoint]\n",
    "\n",
    "history = m.fit(x=np.array(X_train_scaled), y=y_train, batch_size=130,\n",
    "                    epochs=300, verbose=True,\n",
    "                    validation_data=(np.array(X_val_scaled), y_val), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['acc'], label='Accuracy')\n",
    "plt.plot(history.history['val_acc'], label='Validation accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'], label='Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "prediction = m.predict(np.array(X_test_scaled), batch_size=130, verbose=1)\n",
    "y_predict=np.array([ np.argmax(p) for p in prediction])\n",
    "y_test_label = np.array([np.argmax(y) for y in y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "acc = np.sum(y_test_label==y_predict) / float(len(y_test_label))\n",
    "print('Accuracy: {:.2f}'.format(acc))\n",
    "\n",
    "cm = confusion_matrix(y_test_label, y_predict )\n",
    "sns.heatmap(cm, annot=True, annot_kws={\"size\": 14}, fmt='g', linewidths=.5, \n",
    "            yticklabels=label_list,xticklabels=label_list)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
